{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51aacfc5",
   "metadata": {},
   "source": [
    "# Experiment Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f79eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().resolve()\n",
    "if PROJECT_ROOT.name == 'notebooks':\n",
    "    PROJECT_ROOT = PROJECT_ROOT.parent\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "from src.rag_pipeline import rag\n",
    "from src.embedder import generate_query_embedding\n",
    "from src.metrics import (\n",
    "    extract_keywords,\n",
    "    precision_recall_k,\n",
    "    semantic_precision_recall_k,\n",
    "    grounding_score,\n",
    "    estimate_tokens,\n",
    ")\n",
    "from src.self_reflective_rag import self_reflect_rag\n",
    "\n",
    "try:\n",
    "    from src.utils import get_logger\n",
    "    logger = get_logger(__name__)\n",
    "except Exception:\n",
    "    import logging\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    logger = logging.getLogger(__name__)\n",
    "\n",
    "DATA_DIR = PROJECT_ROOT / 'data' / 'processed'\n",
    "EMBEDDINGS_DIR = PROJECT_ROOT / 'embeddings'\n",
    "RESULTS_DIR = PROJECT_ROOT / 'results'\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "chunks_path = DATA_DIR / 'chunks.json'\n",
    "embeddings_path = EMBEDDINGS_DIR / 'embeddings.npy'\n",
    "index_path = EMBEDDINGS_DIR / 'embedding_index.json'\n",
    "\n",
    "if chunks_path.exists():\n",
    "    CHUNKS = json.loads(chunks_path.read_text(encoding='utf-8'))\n",
    "else:\n",
    "    logger.warning('chunks.json not found; using fallback chunks')\n",
    "    CHUNKS = [\n",
    "        {'chunk_id': 'c1', 'text': 'Sprint acceleration depends on shin angles and hip drive.'},\n",
    "        {'chunk_id': 'c2', 'text': 'Defensive pressing intensifies when fatigue sets in.'},\n",
    "        {'chunk_id': 'c3', 'text': 'Heel strike and midfoot strike alter loading rates differently.'},\n",
    "    ]\n",
    "\n",
    "if embeddings_path.exists():\n",
    "    EMBEDDINGS = np.load(embeddings_path)\n",
    "else:\n",
    "    logger.warning('embeddings.npy not found; generating random fallback embeddings')\n",
    "    EMBEDDINGS = np.random.rand(len(CHUNKS), 384)\n",
    "\n",
    "if index_path.exists():\n",
    "    INDEX_MAP = json.loads(index_path.read_text(encoding='utf-8'))\n",
    "else:\n",
    "    logger.warning('embedding_index.json not found; creating sequential index map')\n",
    "    INDEX_MAP = {chunk['chunk_id']: idx for idx, chunk in enumerate(CHUNKS)}\n",
    "\n",
    "PROVIDER = 'openai'\n",
    "LLM_MODEL = None\n",
    "EMBED_MODEL = None\n",
    "TOP_K = 5\n",
    "THRESHOLD = 0.5\n",
    "TEST_QUESTIONS = [\n",
    "    \"Which sport has teams of 6 players: football or volleyball?\",\n",
    "    \"At maximal velocity what is the approximate stride length of elite sprinters?\",\n",
    "    \"What tactical innovation is credited to Hungary's Golden Team in the 1950s?\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4164033",
   "metadata": {},
   "source": [
    "# Running Baseline (Vanilla RAG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9e7f998",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_vanilla_rag(question: str) -> Dict[str, Any]:\n",
    "    result = rag(\n",
    "        query=question,\n",
    "        chunks=CHUNKS,\n",
    "        embeddings=EMBEDDINGS,\n",
    "        index_map=INDEX_MAP,\n",
    "        provider=PROVIDER,\n",
    "        embedding_model=EMBED_MODEL,\n",
    "        llm_model=LLM_MODEL,\n",
    "        k=TOP_K,\n",
    "        threshold=THRESHOLD,\n",
    "    )\n",
    "    return {\n",
    "        'answer': result.get('answer', ''),\n",
    "        'chunks': result.get('chunks', []),\n",
    "        'time_ms': result.get('time_ms', 0.0),\n",
    "        'tokens': estimate_tokens(result.get('answer', '')),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ac9116",
   "metadata": {},
   "source": [
    "# Running Self-Reflective RAG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a96998f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_self_reflective_rag(question: str) -> Dict[str, Any]:\n",
    "    query_embedding = generate_query_embedding(question, provider=PROVIDER, model=EMBED_MODEL)\n",
    "    result = self_reflect_rag(\n",
    "        query=question,\n",
    "        chunks=CHUNKS,\n",
    "        query_embedding=query_embedding,\n",
    "        embeddings=EMBEDDINGS,\n",
    "        index_map=INDEX_MAP,\n",
    "        provider=PROVIDER,\n",
    "        llm_model=LLM_MODEL,\n",
    "        temperature=1.0,\n",
    "        k=TOP_K,\n",
    "        threshold=THRESHOLD,\n",
    "    )\n",
    "    total_time = sum(result.get('timings', {}).values())\n",
    "    refined_answer = result.get('refined_answer', '')\n",
    "    return {\n",
    "        'refined_answer': refined_answer,\n",
    "        'initial_answer': result.get('initial_answer', ''),\n",
    "        'chunks': result.get('retrieved_chunks', []),\n",
    "        'timings': result.get('timings', {}),\n",
    "        'time_ms': total_time,\n",
    "        'tokens': estimate_tokens(refined_answer),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db7516a",
   "metadata": {},
   "source": [
    "# Metrics: Precision/Recall/Grounding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c55acc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-11-25 23:09:09][INFO][src.rag_pipeline] RAG | start | query_len=59 chunks=22\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:09:09][INFO][src.embedder] EMBED | query embedding | provider=openai model=text-embedding-3-small\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-11-25 23:09:11][INFO][httpx] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:09:11][INFO][src.rag_pipeline] RAG | embedding | provider=openai model=text-embedding-3-small time=1732.38 ms\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:09:11][INFO][src.retriever] RETRIEVE | start | vectors=22 k=5 threshold=0.50\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:09:11][INFO][src.retriever] RETRIEVE | threshold filtering | threshold=0.50 passed=1\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:09:11][INFO][src.retriever] RETRIEVE | top_k selected | [{'chunk_id': '4863e5e6-b23f-4b40-a27f-c52d24bd8e84', 'score': 0.5343}]\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:09:11][INFO][src.rag_pipeline] RAG | retrieve | retrieved=1 time=8.75 ms threshold=0.50\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:09:11][INFO][src.llm_orchestrator] LLM | provider=openai model=gpt-5-nano context_chunks=1 context_chars=2819\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:09:11][INFO][src.llm_orchestrator] LLM | prompt_len=3027 approx_tokens=435\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:09:11][INFO][src.llm_orchestrator] LLM | Sending request to OpenAI question: You answer based only on the context below.\n",
      "If the...\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:09:15][INFO][httpx] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:09:15][INFO][src.llm_orchestrator] LLM | OpenAI request completed in 4110.94 ms\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:09:15][INFO][src.llm_orchestrator] LLM | OpenAI response: Volleyball.\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:09:15][INFO][src.llm_orchestrator] LLM | answer size: 11 chars approx_tokens=1\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:09:15][INFO][src.rag_pipeline] RAG | llm | provider=openai model=gpt-5-nano time=4142.58 ms\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:09:15][INFO][src.rag_pipeline] RAG | answer | length=11 tokens≈1\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:09:15][INFO][src.rag_pipeline] RAG | complete | total_time=5890.33 ms\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:09:15][INFO][src.embedder] EMBED | query embedding | provider=openai model=text-embedding-3-small\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-11-25 23:09:15][INFO][httpx] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:09:15][INFO][src.self_reflective_rag] REFLECT | start | query_len=59 chunks=22\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:09:15][INFO][src.retriever] RETRIEVE | start | vectors=22 k=5 threshold=0.50\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:09:15][INFO][src.retriever] RETRIEVE | threshold filtering | threshold=0.50 passed=1\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:09:15][INFO][src.retriever] RETRIEVE | top_k selected | [{'chunk_id': '4863e5e6-b23f-4b40-a27f-c52d24bd8e84', 'score': 0.5343}]\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:09:15][INFO][src.self_reflective_rag] REFLECT | retrieval | retrieved=1 time=2.23 ms threshold=0.50\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:09:15][INFO][src.llm_orchestrator] LLM | provider=openai model=gpt-5-nano context_chunks=1 context_chars=2819\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:09:15][INFO][src.llm_orchestrator] LLM | prompt_len=3027 approx_tokens=435\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:09:15][INFO][src.llm_orchestrator] LLM | Sending request to OpenAI question: You answer based only on the context below.\n",
      "If the...\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:09:18][INFO][httpx] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:09:18][INFO][src.llm_orchestrator] LLM | OpenAI request completed in 3303.91 ms\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:09:18][INFO][src.llm_orchestrator] LLM | OpenAI response: Volleyball.\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:09:18][INFO][src.llm_orchestrator] LLM | answer size: 11 chars approx_tokens=1\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:09:18][INFO][src.self_reflective_rag] REFLECT | initial answer | time=3322.88 ms\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:09:18][INFO][src.llm_orchestrator] LLM | provider=openai model=gpt-5-nano context_chunks=0 context_chars=0\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:09:18][INFO][src.llm_orchestrator] LLM | prompt_len=3558 approx_tokens=505\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:09:18][INFO][src.llm_orchestrator] LLM | Sending request to OpenAI question: You answer based only on the context below.\n",
      "If the...\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:09:35][INFO][httpx] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:09:35][INFO][src.llm_orchestrator] LLM | OpenAI request completed in 16449.78 ms\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:09:35][INFO][src.llm_orchestrator] LLM | OpenAI response: {\n",
      "  \"missing_context\": [\n",
      "    \"Specific aspects from the context that the answer should engage with to demonstrate understanding, such as: court dimensions (18m x 9m), net height (men 2.43 m, women 2.24 m), ball characteristics (circumference, weight, pressure), team composition and rotation, scoring rules, fault interpretations, and libero/serve rules.\",\n",
      "    \"Practical implications and variations mentioned (e.g., minor league differences in challenge protocols or libero serving) that the answer could reference.\"\n",
      "  ],\n",
      "  \"conflicts\": [],\n",
      "  \"logic_issues\": [\n",
      "    \"The answer consists of a single word with no justification or connection to the detailed rules described in the context.\"\n",
      "  ],\n",
      "  \"hallucinations\": [],\n",
      "  \"precision_warnings\": [\n",
      "    \"The single-term answer 'Volleyball.' is vague and does not specify which aspect of the context it addresses, reducing usefulness and clarity.\"\n",
      "  ],\n",
      "  \"language_problems\": [\n",
      "    \"Minimal linguistic issue: the word 'Volleyball' followed by a period is a valid but structurally incomplete fragment.\"\n",
      "  ],\n",
      "  \"reasoning_gaps\": [\n",
      "    \"No reasoning steps or justification are provided to link the term to the detailed regulatory content in the context.\"\n",
      "  ]\n",
      "}\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:09:35][INFO][src.llm_orchestrator] LLM | answer size: 1201 chars approx_tokens=163\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:09:35][INFO][src.self_reflective_rag] REFLECT | critique raw response: {\n",
      "  \"missing_context\": [\n",
      "    \"Specific aspects from the context that the answer should engage with to demonstrate understanding, such as: court dimensions (18m x 9m), net height (men 2.43 m, women 2.24 m), ball characteristics (circumference, weight, pressure), team composition and rotation, scoring rules, fault interpretations, and libero/serve rules.\",\n",
      "    \"Practical implications and variations mentioned (e.g., minor league differences in challenge protocols or libero serving) that the answer could reference.\"\n",
      "  ],\n",
      "  \"conflicts\": [],\n",
      "  \"logic_issues\": [\n",
      "    \"The answer consists of a single word with no justification or connection to the detailed rules described in the context.\"\n",
      "  ],\n",
      "  \"hallucinations\": [],\n",
      "  \"precision_warnings\": [\n",
      "    \"The single-term answer 'Volleyball.' is vague and does not specify which aspect of the context it addresses, reducing usefulness and clarity.\"\n",
      "  ],\n",
      "  \"language_problems\": [\n",
      "    \"Minimal linguistic issue: the word 'Volleyball' followed by a period is a valid but structurally incomplete fragment.\"\n",
      "  ],\n",
      "  \"reasoning_gaps\": [\n",
      "    \"No reasoning steps or justification are provided to link the term to the detailed regulatory content in the context.\"\n",
      "  ]\n",
      "}\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:09:35][INFO][src.self_reflective_rag] REFLECT | critique phase | time=16492.23 ms\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:09:35][INFO][src.llm_orchestrator] LLM | provider=openai model=gpt-5-nano context_chunks=0 context_chars=0\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:09:35][INFO][src.llm_orchestrator] LLM | prompt_len=4543 approx_tokens=644\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:09:35][INFO][src.llm_orchestrator] LLM | Sending request to OpenAI question: You answer based only on the context below.\n",
      "If the...\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:09:56][INFO][httpx] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:09:56][INFO][src.llm_orchestrator] LLM | OpenAI request completed in 20845.01 ms\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:09:56][INFO][src.llm_orchestrator] LLM | OpenAI response: Volleyball.\n",
      "\n",
      "Key points grounded in the provided context:\n",
      "- Governing body and aim: Volleyball is regulated by the FIVB. The core objective is to keep the ball off the ground on your side and send it legally over the net.\n",
      "- Court and zones: Standard court is 18 meters by 9 meters, divided by the net. The front (attack) zone extends from the centerline to the 3-meter line; the back zone runs from the 3-meter line to the endline. Boundary lines are in play.\n",
      "- Net height: 2.43 meters for men and 2.24 meters for women (youth, masters, and recreational leagues may use lower heights). Antennae define the vertical boundaries of legal play.\n",
      "- Ball characteristics: A volleyball is 65–67 cm in circumference, weighs 260–280 g, and requires internal pressure around 0.30–0.325 kg/cm².\n",
      "- Team composition and rules: A standard on-court team consists of six players. The rules cover rotation, contact legality, fault interpretation, and the scoring structure. Some leagues may have minor variations (e.g., challenge review protocols or libero-serving permissions).\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:09:56][INFO][src.llm_orchestrator] LLM | answer size: 1060 chars approx_tokens=171\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:09:56][INFO][src.self_reflective_rag] REFLECT | refinement | time=20865.99 ms\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:09:56][INFO][src.self_reflective_rag] REFLECT | final answer | length=1060 tokens≈171\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:09:56][INFO][src.self_reflective_rag] REFLECT | summary | total=40688.69 ms initial=3322.88 critique=16492.23 refined=20865.99 retrieval=2.23\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:09:56][INFO][src.embedder] EMBED | query embedding | provider=openai model=text-embedding-3-small\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-11-25 23:09:56][INFO][httpx] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:09:56][INFO][src.embedder] EMBED | query embedding | provider=openai model=text-embedding-3-small\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:09:56][INFO][httpx] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:09:56][INFO][src.rag_pipeline] RAG | start | query_len=77 chunks=22\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:09:56][INFO][src.embedder] EMBED | query embedding | provider=openai model=text-embedding-3-small\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-11-25 23:09:57][INFO][httpx] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:09:57][INFO][src.rag_pipeline] RAG | embedding | provider=openai model=text-embedding-3-small time=438.42 ms\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:09:57][INFO][src.retriever] RETRIEVE | start | vectors=22 k=5 threshold=0.50\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:09:57][INFO][src.retriever] RETRIEVE | threshold filtering | threshold=0.50 passed=2\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:09:57][INFO][src.retriever] RETRIEVE | top_k selected | [{'chunk_id': 'cba1976b-e193-4a5a-ac04-7454c53dff73', 'score': 0.6261}, {'chunk_id': 'f5dcd8bd-bd60-4ca7-972f-37e982cb32a3', 'score': 0.6087}]\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:09:57][INFO][src.rag_pipeline] RAG | retrieve | retrieved=2 time=3.64 ms threshold=0.50\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:09:57][INFO][src.llm_orchestrator] LLM | provider=openai model=gpt-5-nano context_chunks=2 context_chars=5103\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:09:57][INFO][src.llm_orchestrator] LLM | prompt_len=5329 approx_tokens=838\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:09:57][INFO][src.llm_orchestrator] LLM | Sending request to OpenAI question: You answer based only on the context below.\n",
      "If the...\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:00][INFO][httpx] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:00][INFO][src.llm_orchestrator] LLM | OpenAI request completed in 2832.57 ms\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:00][INFO][src.llm_orchestrator] LLM | OpenAI response: About 2.3 meters per stride; taller athletes indoors may approach ~2.4 meters.\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:00][INFO][src.llm_orchestrator] LLM | answer size: 78 chars approx_tokens=12\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:00][INFO][src.rag_pipeline] RAG | llm | provider=openai model=gpt-5-nano time=2868.49 ms\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:00][INFO][src.rag_pipeline] RAG | answer | length=78 tokens≈12\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:00][INFO][src.rag_pipeline] RAG | complete | total_time=3316.38 ms\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:00][INFO][src.embedder] EMBED | query embedding | provider=openai model=text-embedding-3-small\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-11-25 23:10:00][INFO][httpx] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:00][INFO][src.self_reflective_rag] REFLECT | start | query_len=77 chunks=22\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:00][INFO][src.retriever] RETRIEVE | start | vectors=22 k=5 threshold=0.50\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:00][INFO][src.retriever] RETRIEVE | threshold filtering | threshold=0.50 passed=2\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:00][INFO][src.retriever] RETRIEVE | top_k selected | [{'chunk_id': 'cba1976b-e193-4a5a-ac04-7454c53dff73', 'score': 0.6261}, {'chunk_id': 'f5dcd8bd-bd60-4ca7-972f-37e982cb32a3', 'score': 0.6088}]\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:00][INFO][src.self_reflective_rag] REFLECT | retrieval | retrieved=2 time=7.15 ms threshold=0.50\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:00][INFO][src.llm_orchestrator] LLM | provider=openai model=gpt-5-nano context_chunks=2 context_chars=5103\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:00][INFO][src.llm_orchestrator] LLM | prompt_len=5329 approx_tokens=838\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:00][INFO][src.llm_orchestrator] LLM | Sending request to OpenAI question: You answer based only on the context below.\n",
      "If the...\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:04][INFO][httpx] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:04][INFO][src.llm_orchestrator] LLM | OpenAI request completed in 3403.97 ms\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:04][INFO][src.llm_orchestrator] LLM | OpenAI response: About 2.3 meters (taller athletes may approach ~2.4 meters indoors).\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:04][INFO][src.llm_orchestrator] LLM | answer size: 68 chars approx_tokens=10\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:04][INFO][src.self_reflective_rag] REFLECT | initial answer | time=3447.38 ms\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:04][INFO][src.llm_orchestrator] LLM | provider=openai model=gpt-5-nano context_chunks=0 context_chars=0\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:04][INFO][src.llm_orchestrator] LLM | prompt_len=5899 approx_tokens=915\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:04][INFO][src.llm_orchestrator] LLM | Sending request to OpenAI question: You answer based only on the context below.\n",
      "If the...\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:11][INFO][httpx] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:11][INFO][src.llm_orchestrator] LLM | OpenAI request completed in 7658.12 ms\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:11][INFO][src.llm_orchestrator] LLM | OpenAI response: {\n",
      "  \"missing_context\": [],\n",
      "  \"conflicts\": [],\n",
      "  \"logic_issues\": [],\n",
      "  \"hallucinations\": [],\n",
      "  \"precision_warnings\": [],\n",
      "  \"language_problems\": [],\n",
      "  \"reasoning_gaps\": []\n",
      "}\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:11][INFO][src.llm_orchestrator] LLM | answer size: 171 chars approx_tokens=16\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:11][INFO][src.self_reflective_rag] REFLECT | critique raw response: {\n",
      "  \"missing_context\": [],\n",
      "  \"conflicts\": [],\n",
      "  \"logic_issues\": [],\n",
      "  \"hallucinations\": [],\n",
      "  \"precision_warnings\": [],\n",
      "  \"language_problems\": [],\n",
      "  \"reasoning_gaps\": []\n",
      "}\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:11][INFO][src.self_reflective_rag] REFLECT | critique phase | time=7677.15 ms\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:11][INFO][src.llm_orchestrator] LLM | provider=openai model=gpt-5-nano context_chunks=0 context_chars=0\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:11][INFO][src.llm_orchestrator] LLM | prompt_len=5854 approx_tokens=907\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:11][INFO][src.llm_orchestrator] LLM | Sending request to OpenAI question: You answer based only on the context below.\n",
      "If the...\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:23][INFO][httpx] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:23][INFO][src.llm_orchestrator] LLM | OpenAI request completed in 12101.83 ms\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:23][INFO][src.llm_orchestrator] LLM | OpenAI response: Stride length during maximal velocity typically expands toward 2.3 m, with taller athletes approaching about 2.4 m indoors. Reaching this length depends on timely front-side mechanics so the thigh reaches hip height before whipping downward. Cadence management is debated: some coaches target about 4.6 strides per second to ensure length changes come from improved force application rather than deliberate over-striding, while others allow a slight cadence reduction if it yields more powerful hip extension. Both approaches can work when supported by intentional feedback loops and video metrics. Arm mechanics also influence stride length: shortening the forward swing can lower vertical oscillation, whereas a full-amplitude swing supports torso elastic recoil.\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:23][INFO][src.llm_orchestrator] LLM | answer size: 765 chars approx_tokens=109\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:23][INFO][src.self_reflective_rag] REFLECT | refinement | time=12118.21 ms\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:23][INFO][src.self_reflective_rag] REFLECT | final answer | length=765 tokens≈109\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:23][INFO][src.self_reflective_rag] REFLECT | summary | total=23258.24 ms initial=3447.38 critique=7677.15 refined=12118.21 retrieval=7.15\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:23][INFO][src.embedder] EMBED | query embedding | provider=openai model=text-embedding-3-small\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-11-25 23:10:24][INFO][httpx] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:24][INFO][src.embedder] EMBED | query embedding | provider=openai model=text-embedding-3-small\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:24][INFO][httpx] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:24][INFO][src.rag_pipeline] RAG | start | query_len=75 chunks=22\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:24][INFO][src.embedder] EMBED | query embedding | provider=openai model=text-embedding-3-small\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-11-25 23:10:25][INFO][httpx] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:25][INFO][src.rag_pipeline] RAG | embedding | provider=openai model=text-embedding-3-small time=403.50 ms\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:25][INFO][src.retriever] RETRIEVE | start | vectors=22 k=5 threshold=0.50\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:25][INFO][src.retriever] RETRIEVE | threshold filtering | threshold=0.50 passed=1\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:25][INFO][src.retriever] RETRIEVE | top_k selected | [{'chunk_id': 'b8030f14-9641-4509-bc2b-70260bf08b8a', 'score': 0.5191}]\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:25][INFO][src.rag_pipeline] RAG | retrieve | retrieved=1 time=1.72 ms threshold=0.50\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:25][INFO][src.llm_orchestrator] LLM | provider=openai model=gpt-5-nano context_chunks=1 context_chars=3039\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:25][INFO][src.llm_orchestrator] LLM | prompt_len=3263 approx_tokens=437\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:25][INFO][src.llm_orchestrator] LLM | Sending request to OpenAI question: You answer based only on the context below.\n",
      "If the...\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:27][INFO][httpx] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:27][INFO][src.llm_orchestrator] LLM | OpenAI request completed in 2900.09 ms\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:28][INFO][src.llm_orchestrator] LLM | OpenAI response: The use of a false nine (with Nándor Hidegkuti as a prototype).\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:28][INFO][src.llm_orchestrator] LLM | answer size: 63 chars approx_tokens=12\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:28][INFO][src.rag_pipeline] RAG | llm | provider=openai model=gpt-5-nano time=2916.43 ms\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:28][INFO][src.rag_pipeline] RAG | answer | length=63 tokens≈12\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:28][INFO][src.rag_pipeline] RAG | complete | total_time=3324.36 ms\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:28][INFO][src.embedder] EMBED | query embedding | provider=openai model=text-embedding-3-small\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-11-25 23:10:28][INFO][httpx] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:28][INFO][src.self_reflective_rag] REFLECT | start | query_len=75 chunks=22\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:28][INFO][src.retriever] RETRIEVE | start | vectors=22 k=5 threshold=0.50\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:28][INFO][src.retriever] RETRIEVE | threshold filtering | threshold=0.50 passed=1\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:28][INFO][src.retriever] RETRIEVE | top_k selected | [{'chunk_id': 'b8030f14-9641-4509-bc2b-70260bf08b8a', 'score': 0.5191}]\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:28][INFO][src.self_reflective_rag] REFLECT | retrieval | retrieved=1 time=4.65 ms threshold=0.50\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:28][INFO][src.llm_orchestrator] LLM | provider=openai model=gpt-5-nano context_chunks=1 context_chars=3039\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:28][INFO][src.llm_orchestrator] LLM | prompt_len=3263 approx_tokens=437\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:28][INFO][src.llm_orchestrator] LLM | Sending request to OpenAI question: You answer based only on the context below.\n",
      "If the...\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:32][INFO][httpx] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:32][INFO][src.llm_orchestrator] LLM | OpenAI request completed in 4538.26 ms\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:32][INFO][src.llm_orchestrator] LLM | OpenAI response: The use of a false nine — with Nándor Hidegkuti as the prototype — interchanging positions to draw defenders out of shape and open space for wingers and midfielders.\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:32][INFO][src.llm_orchestrator] LLM | answer size: 165 chars approx_tokens=29\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:32][INFO][src.self_reflective_rag] REFLECT | initial answer | time=4556.04 ms\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:32][INFO][src.llm_orchestrator] LLM | provider=openai model=gpt-5-nano context_chunks=0 context_chars=0\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:32][INFO][src.llm_orchestrator] LLM | prompt_len=3932 approx_tokens=533\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:32][INFO][src.llm_orchestrator] LLM | Sending request to OpenAI question: You answer based only on the context below.\n",
      "If the...\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:44][INFO][httpx] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:44][INFO][src.llm_orchestrator] LLM | OpenAI request completed in 12109.64 ms\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:45][INFO][src.llm_orchestrator] LLM | OpenAI response: {\n",
      "  \"missing_context\": [],\n",
      "  \"conflicts\": [],\n",
      "  \"logic_issues\": [],\n",
      "  \"hallucinations\": [],\n",
      "  \"precision_warnings\": [],\n",
      "  \"language_problems\": [],\n",
      "  \"reasoning_gaps\": []\n",
      "}\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:45][INFO][src.llm_orchestrator] LLM | answer size: 171 chars approx_tokens=16\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:45][INFO][src.self_reflective_rag] REFLECT | critique raw response: {\n",
      "  \"missing_context\": [],\n",
      "  \"conflicts\": [],\n",
      "  \"logic_issues\": [],\n",
      "  \"hallucinations\": [],\n",
      "  \"precision_warnings\": [],\n",
      "  \"language_problems\": [],\n",
      "  \"reasoning_gaps\": []\n",
      "}\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:45][INFO][src.self_reflective_rag] REFLECT | critique phase | time=12131.32 ms\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:45][INFO][src.llm_orchestrator] LLM | provider=openai model=gpt-5-nano context_chunks=0 context_chars=0\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:45][INFO][src.llm_orchestrator] LLM | prompt_len=3887 approx_tokens=525\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:45][INFO][src.llm_orchestrator] LLM | Sending request to OpenAI question: You answer based only on the context below.\n",
      "If the...\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:52][INFO][httpx] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:52][INFO][src.llm_orchestrator] LLM | OpenAI request completed in 7327.51 ms\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:52][INFO][src.llm_orchestrator] LLM | OpenAI response: During Hungary's Golden Team era in the 1950s, Nándor Hidegkuti functioned as the prototype “false nine.” Players frequently interchanged positions, using the roaming striker to draw defenders out of shape and open space for wingers and midfielders, thereby disrupting conventional man-marking systems.\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:52][INFO][src.llm_orchestrator] LLM | answer size: 302 chars approx_tokens=42\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:52][INFO][src.self_reflective_rag] REFLECT | refinement | time=7347.52 ms\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:52][INFO][src.self_reflective_rag] REFLECT | final answer | length=302 tokens≈42\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:52][INFO][src.self_reflective_rag] REFLECT | summary | total=24045.40 ms initial=4556.04 critique=12131.32 refined=7347.52 retrieval=4.65\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:52][INFO][src.embedder] EMBED | query embedding | provider=openai model=text-embedding-3-small\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-11-25 23:10:52][INFO][httpx] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:52][INFO][src.embedder] EMBED | query embedding | provider=openai model=text-embedding-3-small\u001b[0m\n",
      "\u001b[32m[2025-11-25 23:10:53][INFO][httpx] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "records: List[Dict[str, Any]] = []\n",
    "for question in TEST_QUESTIONS:\n",
    "    keywords = extract_keywords(question)\n",
    "    vanilla_result = run_vanilla_rag(question)\n",
    "    print(\"-\" * 40)\n",
    "    reflective_result = run_self_reflective_rag(question)\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    keyword_precision_vanilla, keyword_recall_vanilla = precision_recall_k(\n",
    "        query=question,\n",
    "        retrieved_chunks=vanilla_result['chunks'],\n",
    "        all_chunks=CHUNKS,\n",
    "        k=TOP_K,\n",
    "    )\n",
    "\n",
    "    vanilla_answer_embedding = generate_query_embedding(vanilla_result['answer'], provider=PROVIDER, model=EMBED_MODEL)\n",
    "    semantic_precision_vanilla, semantic_recall_vanilla = semantic_precision_recall_k(\n",
    "        answer_embedding=vanilla_answer_embedding,\n",
    "        retrieved_chunks=vanilla_result['chunks'],\n",
    "        all_chunks=CHUNKS,\n",
    "        embeddings=EMBEDDINGS,\n",
    "        index_map=INDEX_MAP,\n",
    "        k=TOP_K,\n",
    "    )\n",
    "\n",
    "    keyword_precision, keyword_recall = precision_recall_k(\n",
    "        query=question,\n",
    "        retrieved_chunks=reflective_result['chunks'],\n",
    "        all_chunks=CHUNKS,\n",
    "        k=TOP_K,\n",
    "    )\n",
    "\n",
    "    answer_embedding = generate_query_embedding(reflective_result['refined_answer'], provider=PROVIDER, model=EMBED_MODEL)\n",
    "    semantic_precision, semantic_recall = semantic_precision_recall_k(\n",
    "        answer_embedding=answer_embedding,\n",
    "        retrieved_chunks=reflective_result['chunks'],\n",
    "        all_chunks=CHUNKS,\n",
    "        embeddings=EMBEDDINGS,\n",
    "        index_map=INDEX_MAP,\n",
    "        k=TOP_K,\n",
    "    )\n",
    "\n",
    "    grounding = grounding_score(reflective_result['refined_answer'], reflective_result['chunks'])\n",
    "\n",
    "    records.append({\n",
    "        'question': question,\n",
    "        'time_vanilla': vanilla_result['time_ms'],\n",
    "        'time_reflective': reflective_result['time_ms'],\n",
    "        'tokens_vanilla': vanilla_result['tokens'],\n",
    "        'tokens_reflective': reflective_result['tokens'],\n",
    "        'grounding_reflective': grounding,\n",
    "        'keyword_precision_vanilla_k': keyword_precision_vanilla,\n",
    "        'keyword_recall_vanilla_k': keyword_recall_vanilla,\n",
    "        'semantic_precision_vanilla_k': semantic_precision_vanilla,\n",
    "        'semantic_recall_vanilla_k': semantic_recall_vanilla,\n",
    "        'keyword_precision_k': keyword_precision,\n",
    "        'keyword_recall_k': keyword_recall,\n",
    "        'semantic_precision_k': semantic_precision,\n",
    "        'semantic_recall_k': semantic_recall,\n",
    "    })\n",
    "    print(\"\\n\" + \"-\" * 40 + \"\\n\")\n",
    "\n",
    "df = pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f59cedbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>time_vanilla</th>\n",
       "      <th>time_reflective</th>\n",
       "      <th>tokens_vanilla</th>\n",
       "      <th>tokens_reflective</th>\n",
       "      <th>grounding_reflective</th>\n",
       "      <th>keyword_precision_vanilla_k</th>\n",
       "      <th>keyword_recall_vanilla_k</th>\n",
       "      <th>semantic_precision_vanilla_k</th>\n",
       "      <th>semantic_recall_vanilla_k</th>\n",
       "      <th>keyword_precision_k</th>\n",
       "      <th>keyword_recall_k</th>\n",
       "      <th>semantic_precision_k</th>\n",
       "      <th>semantic_recall_k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Which sport has teams of 6 players: football o...</td>\n",
       "      <td>5890.3348</td>\n",
       "      <td>81372.0162</td>\n",
       "      <td>1</td>\n",
       "      <td>171</td>\n",
       "      <td>0.840491</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>At maximal velocity what is the approximate st...</td>\n",
       "      <td>3316.3843</td>\n",
       "      <td>46508.1296</td>\n",
       "      <td>12</td>\n",
       "      <td>109</td>\n",
       "      <td>0.844037</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What tactical innovation is credited to Hungar...</td>\n",
       "      <td>3324.3632</td>\n",
       "      <td>48084.9331</td>\n",
       "      <td>12</td>\n",
       "      <td>42</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  time_vanilla  \\\n",
       "0  Which sport has teams of 6 players: football o...     5890.3348   \n",
       "1  At maximal velocity what is the approximate st...     3316.3843   \n",
       "2  What tactical innovation is credited to Hungar...     3324.3632   \n",
       "\n",
       "   time_reflective  tokens_vanilla  tokens_reflective  grounding_reflective  \\\n",
       "0       81372.0162               1                171              0.840491   \n",
       "1       46508.1296              12                109              0.844037   \n",
       "2       48084.9331              12                 42              0.755556   \n",
       "\n",
       "   keyword_precision_vanilla_k  keyword_recall_vanilla_k  \\\n",
       "0                          0.2                  0.058824   \n",
       "1                          0.4                  0.250000   \n",
       "2                          0.2                  0.058824   \n",
       "\n",
       "   semantic_precision_vanilla_k  semantic_recall_vanilla_k  \\\n",
       "0                           0.2                        1.0   \n",
       "1                           0.2                        1.0   \n",
       "2                           0.0                        0.0   \n",
       "\n",
       "   keyword_precision_k  keyword_recall_k  semantic_precision_k  \\\n",
       "0                  0.2          0.058824                   0.2   \n",
       "1                  0.4          0.250000                   0.4   \n",
       "2                  0.2          0.058824                   0.0   \n",
       "\n",
       "   semantic_recall_k  \n",
       "0           0.200000  \n",
       "1           0.666667  \n",
       "2           0.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3c2067",
   "metadata": {},
   "source": [
    "# Saving Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0426bc29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved results to: C:\\Users\\tomasz.makowski.2\\Desktop\\SemesterII\\ComputationalIntelligence\\Project\\agentic-rag-architectures\\results\\experiment_results.csv and C:\\Users\\tomasz.makowski.2\\Desktop\\SemesterII\\ComputationalIntelligence\\Project\\agentic-rag-architectures\\results\\experiment_results.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'avg_time_vanilla': 4177.027433295734,\n",
       " 'avg_time_reflective': 58655.02629999537,\n",
       " 'avg_grounding_reflective': 0.8133610167830915}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_path = RESULTS_DIR / 'experiment_results.csv'\n",
    "json_path = RESULTS_DIR / 'experiment_results.json'\n",
    "df.to_csv(csv_path, index=False)\n",
    "json_path.write_text(json.dumps(records, ensure_ascii=False, indent=2), encoding='utf-8')\n",
    "summary = {\n",
    "    'avg_time_vanilla': float(df['time_vanilla'].mean()) if not df.empty else 0.0,\n",
    "    'avg_time_reflective': float(df['time_reflective'].mean()) if not df.empty else 0.0,\n",
    "    'avg_grounding_reflective': float(df['grounding_reflective'].mean()) if not df.empty else 0.0,\n",
    "}\n",
    "print('Saved results to:', csv_path, 'and', json_path)\n",
    "summary\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ara",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
